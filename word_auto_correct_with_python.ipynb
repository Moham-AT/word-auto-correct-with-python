{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word auto-correct with python",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmXgJrcTPkIf7oBNqP/VuE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamad1371/word-auto-correct-with-python/blob/main/word_auto_correct_with_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "P4ckRmcVA2gc",
        "outputId": "f4abf82d-0577-4b0f-c505-6d2f389a8d55"
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def delete_letter(word):\n",
        "    \n",
        "    delete_l = []\n",
        "    word = word.lower()\n",
        "    for index in range(len(word)):\n",
        "        s = word[:index] + word[index + 1:]\n",
        "        if s not in delete_l and len(s)>0:\n",
        "            delete_l.append(s)\n",
        "    return delete_l\n",
        "\n",
        "def replace_letter(word):\n",
        "    replace_l=[]\n",
        "    word = word.lower()\n",
        "    for i in range(len(word)):\n",
        "        for j in range(ord('a'), ord('z')+1):\n",
        "            w = word[:i] + chr(j) + word[i+1:]\n",
        "            if w not in replace_l and w != word:\n",
        "                replace_l.append(w)\n",
        "\n",
        "    return replace_l\n",
        "    \n",
        "def insert_letter(word):\n",
        "    insert_l = []\n",
        "    word = word.lower()\n",
        "    word_list = list(word)\n",
        "    for i in range(len(word)+1):\n",
        "        for j in range(ord('a'), ord('z')+1):\n",
        "            word_list.insert(i,chr(j))\n",
        "            if ''.join(word_list) not in insert_l:\n",
        "                insert_l.append(''.join(word_list))\n",
        "            del(word_list[i])\n",
        "\n",
        "    return insert_l\n",
        "\n",
        "def calculate_cost(token1, token2):\n",
        "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
        "    for t1 in range(len(token1) + 1):\n",
        "        distances[t1][0] = t1\n",
        "    for t2 in range(len(token2) + 1):\n",
        "        distances[0][t2] = t2    \n",
        "\n",
        "    a = 0\n",
        "    b = 0\n",
        "    c = 0\n",
        "    \n",
        "    for t1 in range(1, len(token1) + 1):\n",
        "        for t2 in range(1, len(token2) + 1):\n",
        "            if (token1[t1-1] == token2[t2-1]):\n",
        "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
        "            else:\n",
        "                a = distances[t1][t2 - 1]\n",
        "                b = distances[t1 - 1][t2]\n",
        "                c = distances[t1 - 1][t2 - 1]\n",
        "                \n",
        "                if (a <= b and a <= c):\n",
        "                    distances[t1][t2] = a + 1\n",
        "                elif (b <= a and b <= c):\n",
        "                    distances[t1][t2] = b + 1\n",
        "                else:\n",
        "                    distances[t1][t2] = c + 2\n",
        "\n",
        "    return distances[len(token1)][len(token2)]    \n",
        "\n",
        "\n",
        "\n",
        "def edit_one_letter(word):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
        "    Output:\n",
        "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
        "    \"\"\"\n",
        "    edit_one_set = set()\n",
        "    edit_one_set.update(delete_letter(word))\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "    return edit_one_set\n",
        "    \n",
        "def edit_two_letters(word):\n",
        "    edit_two_set = set()\n",
        "    all_1_changed = edit_one_letter(word)\n",
        "    for i in all_1_changed:\n",
        "        edit_two_set.update(delete_letter(i), replace_letter(i), insert_letter(i))\n",
        "\n",
        "    return edit_two_set   \n",
        "\n",
        "\n",
        "def autoCorrect(word):\n",
        "\n",
        "    with open('shakespeare.txt') as f:\n",
        "        data = f.read()\n",
        "\n",
        "    data = re.sub('[^A-Za-z0-9]+', ' ', data)    \n",
        "    all_refwords_list = re.split(r'\\W+', data)\n",
        "    all_refwords_set = set(all_refwords_list)\n",
        "    one_change = edit_one_letter(word)\n",
        "    two_change = edit_two_letters(word)\n",
        "    all_1_2_change = one_change.union(two_change)\n",
        "    usable_words  = list(all_1_2_change & all_refwords_set)\n",
        "    repeat_num_dic = dict((i, all_refwords_list.count(i)) for i in usable_words)\n",
        "\n",
        "    distance_dic = {}\n",
        "    for i in repeat_num_dic.keys():\n",
        "        distance_dic[i] = calculate_cost(word, i)\n",
        "    distance_dic = {k: v for k, v in sorted(distance_dic.items(), key=lambda item: item[1])}\n",
        "    special_words = [i for i in distance_dic.keys() if distance_dic[i]==distance_dic[list(distance_dic.keys())[0]]]\n",
        "    \n",
        "    if len(special_words) == 1:\n",
        "        result = special_words[0]\n",
        "\n",
        "    elif  len(special_words) == 0:\n",
        "        print('There is no matching word with less than 4 penalties')\n",
        "        result = None\n",
        "    else:\n",
        "        list_of_best_specils = [[repeat_num_dic[i], i] for i in special_words]\n",
        "        list_of_best_specils = sorted(list_of_best_specils)\n",
        "        result = list_of_best_specils[-1][1]\n",
        "\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "input_word = input('Inter a misspelled word: ')\n",
        "\n",
        "autoCorrect(input_word)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inter a misspelled word: natch\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'snatch'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}